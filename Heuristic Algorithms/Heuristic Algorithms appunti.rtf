{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1040{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.22000}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\qc\f0\fs22\lang16 Appunti di Heuristic Algorithms\par

\pard\sa200\sl276\slmult1\qj Lezione 1 - 29/09/2022\par
[he wanted us to download the lessons]\par
Heuristics algorithms are not for specific problems. They are general ideas that work widely for any possible problem. Then those ideas are adapted to the particual problem. We'll see how we adapt general ideas to specific problems and then evaluate if the algorithm is good or not. First, some historical ideas. Then, we'll see that "heuristics" are used in many contexts. Then, how to evaluate the performance. Heuristic comes from greek that means "I find", based on the famous story of Archimetes and the golden crown. He wanted to understand if that crown was authentic or not. it was based on the volume, measured putting the crown in a "pool". The concept of heuristics go back to the 4th century a.c. about the ideas that help find proofs for math theorems. These ideas were used in 17th century onward. Heuristics were a collection of general ideas, intuitions.\par
The idea of the heuristic algorithms is that we cannot ensure that we will have a good solution, but most of the time will be a good solution (or the correct/best solution). We can use distributions that tell us how much it is likely that we'll get a good solution. We'll talk about some heuristics for some problems. We consider only Combinatorial optimization. We'll only consider heuristics based on solutions and not models. \line Problems in fact can be classified based on the nature of their solution:\line -Decision problems: true or false.\line -Search problems: the solution is any feasible subsystem (that is, satysfing certain conditions).\line -Optimization problems: The solution is the minimum or maximum value of an objective function defined on the feasible subsystems. Usually, optimization and search are tied together.\line -Counting problems: number of feasible subsystem.\line -Enumeration problems: collection of all feasible subsystems.\par
The solutions in a CO problem is a combination. So, a CO problem can also be considered as a Subset Optimization problem. A combination is: we have n elements and take k of them. \par
Solution based heuristics: heuristics where we use and manipulate subsets of the ground set. \par
Metaheuristic is the common name for heuristic algorithms with randomization and/or memory. \par
5 parts of the course. This lesson and tomorrow one is the first part. We concern on what is a CO and its ground set. Also, is your algorithm good or not? This can be discussed at priori or after executions. We can also give a lower bound on the performances of an algorithm. "My algorithm won't give a solution worse thatn half of the optimum", for example. \par
Let's start with a suervey of problems that are examples. \line 1st: knapsack problem. The ground set is the set of objects to put in the knapsack, because a subset of them is a (possible) solution. From now on, we will distinguish the solutions between Feasible and Unfeasible. \line Problem of three points most distant: a ground set (compact) is the set of all points. Another one (that uses the trick) is the set of all triples. How do we represent the FEASIBLE solution? \{A,B,C\} as a vector is an example. Antoher one is an incidence vector: [1,1,1,0,0,0,0] (1 for the points i count, 0 otherwise). \par
In the knapsack, the objective function is ADDITIVE. This means that in the function we have a sum of all the elements of the solution with a function (?).\par
Flat objective functions work bad with the BPP and the PMSP when the exchange heuristic is used, but the same heuristic is good for the Knapsack.\par
\par
Lezione 2 - 30/09/2022\par
Yesterday, we saw four problems of combinatorial optimization. Some questions were: what is the ground set? There are multiple answers and some ground sets are better than others. Let's also ask ourselves some questions about the combinatorial optimization problem. They are related on the representation of the solutions and such. \line Flat representation: bad for exchange heuristics, since different solutions may have the same value.\par
Max-SAT problem. A logical variable is a variable that can be true or false, can only assume two values. Logical variables can be used in logical functions. \par
...\par
16 -> ground set for SAT: for example, cartesian product of variables and B (0,1). Another one, simpler, is one that takes as subset only the true variables. The objective function is not additive since is not a sum over the elements of the solution. We are summing something that is not related to (x_i, b), but to the conjunction of OR formulas. \par
18 -> Do all the tasks (rows) with minimal cost (value for each column). Ground set: set of columns. A subset of them is a possible solution. The OF is additive.\par
19 -> The feasibility test. Is this a subset or a feasible solution? important question. \line Exchange can create feasible or unfeasible solutions, really depends. in PMSM exchange makes always feasible solutions, in BPP it might not. \par
Set covering: each row must be covered at least once.\par
Set packing: each row must be covered at most once.\par
Set partitioning: each row must be covered EXACTLY once. (we always want to maximise the value of the sum of columns).\line\b Can you find a feasible solution? Is there an easy way to find it?\b0  Exchange heuristics start from a solution. Recombination heuristics start from a population of solutions. In this case, it is hard. \line Set covering -> take all columns (first solution)\line Set packing -> take no column (first solution)\line Set partitioning -> Difficult. Feasibility is NP-complete. One thing we can do is: I'm not sure I can find an element in X, but thanks to a relaxation of the feasible region (X') maybe I can find a feasible solution for the relaxation. \par
So, finding a feasible solution and understanding if a solution is feasible is a main concern. \par
25 -> Graph problems: Vertex Cover Problem. Find a set of vertexes that cover all the edges. An edge is covered if one of the vertex it touches is selected for the solution.\par
35 -> can we find a feasible solution? It depends. Is there a Hamiltonian circuit? This is a strong NP-hard question. But if a complete graph is given, we can take any permutation and it is a possible solution. \par
\par
Lezione 3 - 06/10/2022\par
37 -> This problem (CMSTP) is used for connecting servers. NP-hard to find optimal solution. In linear time (with respect to the set x), we can see if the solution is feasible or not. The obj function is the sum of functions over elements of the solution, so it's additive. Also for exchange heuristics is good, but if we exchange an edge with another we have to re-visit most of the graph to see if it is feasible. \line Here we have vertexes that we want to put in subtrees (BPP ispossib\'f2l?). \par
39 -> (Vertex, Subtree). Also with this ground set we can represent a solution. Checking the feasibility? We just count how many vertexes are in a subtree. But this is ok for not exceeding W. We also have to check if all the nodes of the subtree are conneceted and at least one is connected to r. This is more complex. BUT, if it is a complete graph, it's much easier. So, IN SPECIFIC SUBSET INSTANCES OF THIS PROBLEM, this representation is good (very good). How do we compute the cost anyway? We should have edges, that are not given in the representation. So, in order to compute the objective value of a solution x, we have to resolve the MST problem for each subtree. I take the cheapest tree that contains all the nodes belonging to that representation. (MST = Minimum Spanning Tree). Here, the complexity of computing the objective function is not linear, but is costly (not a lot anyway). \par
44 -> So, which representation is the best? Depends. What am I going to evaluate more times? Feasibility or obj. function? That should be the simpler. One can use both representations! ...but that doubles memory and updates to a solution. Is this a disadvantage? Depends. Sometimes, it is convenient to have two representations. It's true that they must be consistend, but one allows easy computation for feasibility and the other for the objective function. \par
43 -> x it's a feasible solution if each vertex has an ongoing and outgoing edge in x. Also, check if the cycles created don't exceed the maximum capacity. Using the other representation: it's easy to compute the weight of each sub-cycle, and if it is complete as a graph it's easy to find the cycle. But, obj function? Solve the TSP for each sub-cycle (NP-complete :( )\line But when we talked about the Max-SAT, we proposed x = subset of variables made true. Another proposal was x = clausles made true. In this last case, the feasibility is SAT. I mean, you'd have to compute a SAT solution to understand if x is a feasible solution for a SAT problem. That's stupid. \line But in 43, if the graph is complete and W is small, it is true that we need to solve TSP for sub-problems, but the instances are so small that we can do it! But the small TSP, how is computed? Exactly or with another heuristic? eh...\line It has been shown that using heuristic to solve those small TSP can lead to good solutions. \par
Slide 03:\par
A priori and a posteriori analysis. Today we talk about cost, tomorrow about quality. \par
2 -> A problem is made by many cases, that are all similar. I have infinite instances, possibly. For each instance, i have a solution. The problem can be seen as a function! I -> S. The problem is a function that maybe we can compute (depends on the instance), but maybe no. \par
3 -> We can have different algorithms for the same problem. \par
4 -> Cost is time and space. It is possible to reduce the use of time by allowing the use of more space and vice-versa. \par
13 -> What if the capacity of KP is small? Well, in that case, even if I have a lot of items (n), the problem is easy, because in general at most two items can stay in the knapsack. In this case, the complexity is quadratic. \par
circa 16 - Parametrized complexity. We have a parameter that affects the complexity.\par
\par
Lezione 4 - 07/10/2022\par
13 and around -> find the worst instance not only with respect to n, but also with respect to k, another parameter. \par
24 -> after describing the probabilistic model, you have to find the expected value over each of the slices, for each value of n. You can build a probabilistic model based on simulations. \par
25 -> Let's talk about (binary) matrices. For the Set Covering Problem, we had columns that cover rows. How can we give a probabilistic model for those matrices?\line -equiprobability: there are 2^mn matrices. If I assume that each of them has the same probability, i compute the complexity starting from this assumption.\line -uniform probability: each cell is set to 1 with a certain probability\line -fixed density: extract a certain numner of cells with a uniform probability and set them to 1. Dense matrix = fast algorithm, sparse matrix = slow algorithm. In fixed density, we have exactly delta ones. In the equiprobability, the process is still random.\par
26 -> the first case is a particular case of the second. \par
29 -> Sat exhibits phase transitions. OCCHIO: the blu part on the right has the same role of the red one on the left, and viceversa. \par
31 -> In heuristics, the concept of complexity is a bit different than the usual one.\par
lez_04\par
2 -> If efficency means low cost, effectiveness means quality of the solution. So, we need the concepts of closeness and frequency. We can also do a priori and a posteriori analysis. A priori means: I prove that my algorithm also gives a solution that has a certain quality.\par
3 -> There are three definitions for the effectiveness of a heuristic optimization algorithm. f_A(I): value given on instance I by my heuristic algorithm A. I'd like this value to be equal to f*(I), the true optimal value of the instance. \line What if you don't know the optimum? You can construct a lower and upper bound for the optimum. \line (Lower bound = dual bound, upper bound = primal bound). \par
4 -> Up until now, the reasonings were based on experimental analysis (particualr instances). Let's do a thoeretical analysis. \line For the minimum coloring graph problem, the minimum number of colors you have is either the dimension of (the maximum degree) the max clique in the graph or that value +1. \line The last inequality tells us that what our heuristic finds is always bounded by a function of n.\par
\par
Lezione 5 - 13/10/2022\par
We've seen a priori study of heuristic algorithms. In particular, a priori cost and effectiveness. \par
4\'b0 slide\par
14 -> Better approx algos but worse time, there is this trade-off in some algorithms. Not all problems can actualy be approximated. \par
13 -> example: the TSP. Inapproximable = can't prove that your algorithm is alpha times the optimum. \par
5\'b0 slide\par
2 -> empirical evaluation of a heuristic algorithm. The thoeretical analysis is complicated, and a precise answer might not be practical. So, we can follow an experimental approach.\par
3 -> Experimental approach is: bserve the field of your study, then build the model. Then, design experiments to evaluate the model, analyse the results and revise the model based on the results until a satisfactory model. The model could be debunked, in that case you modify it. Or, your experiments prove your system to be correct. \par
4 -> we want to find indicies of efficiency and effectiveness of an algorithm. Then, use this indices to compare different algorithms. In this way, you conlcude that an algo is better than another one. Maybe my algo is good on small instances but good on greater instances.\par
5 -> how do we perform experiments? giving a benchmark of instances. Ideally, it is infinite. practically, it's a subset. What subset? It must be representative of the whole set, relating to structural features. The instances should not be too easy or too hard\par
6 -> the environment influence the result and makes it difficult to reproduce precisely the result. \par
7 -> we sould describe the cost and quality of our algorithms. The only time in which we can say that we prefer an algorithm over another is when it takes not much time and the quality is good. Otherwise, the time or the result must be similar to compare the other feature. \par
8 -> statistical model of algorithm performance? We have the domane of instances, and from it we extract a sample set/benchmark. From it, we randomly extract an instance each time we need one. T_A(I) is the computational time that is a random variable. The relative difference delta is also a random variable. \par
9 -> When i try to compute the relative difference, i usually don't have the optimal value So, we have to estimate delta_A(i). So, we need LOWER BOUND and UPPER BOUND, eccoliiiiiiiiii.\line The lower bound is not greater thatn the optimal, while the upper bound is greater than the optimal. \par
10 -> We'll see a lot of pictures. Le'ts see the Runtime Distribution Diagram. It's a plot that on x axis gives a time, on y gives how likely it is to solve an instance that takes that time. Bascially: given instance i, and fixed time x, y is the probability that i will be solved in that time. \par
11 -> Main features: monotone nondecreasing. It's also not continuous. In zero or before 0 the diagram is equal to zero (you need some time to solve the problem). It's also equal to 1 from a certain point on. \par
13 -> up till now, we assumed that the size was fixed. What happened if we allow time to change? Scaling diagram. x = size of the instance. y = time to solve it. \par
15 -> The Solution Quality Distribution is a diagram of the relative difference. \par
\par
Lezione 6 - 14/10/2022\par
Slide 5\'b0\par
10 -> it's a probability distribution function. \par
14 -> number of elementary operation you perform but also time (?). Depends on the computer you do your runs. \par
15 -> Should we fix the size of the instances or not? Depends. A thing you could do is: consider different sizes, and get profiles of the relative differences. \par
18 -> parametric diagrams. Let's fix the size of the instances and build, for each of them, the SQD diagram. This might show us a trend. As you increase the size of your problem, your algorithm becomes less precise and more heuristic (this is something that can happen). \par
19 -> you can use the SQD to compare the performances of different algorithms. Strict dominance: an algorithm is better than another when the relative difference of the first is better than the relative difference of the second on all instances. Strict dominance implies probabilistic dominance. \par
slide 6\'b0\par
2 -> Compact statistical descriptions. Mean and Variance depend a lot on outliers, unfortunately. The average is used, the variance is less used.\par
3 -> The median divides in two the benchmark. Compute minimum, mazimum, median, etc.. might be a question. Usefulness of this diagram? First: we can observe that this diagram is a simplification of the SQD. Till the minimum, the SQD would be 0. from minimum to lower quartile, the SQD goes up to 25%. Then, from it to the median, goes up to 50%, and so on. From the SQD, you can have the box plot, too. We can use box plot to compare algorithms.\par
4 -> for different algorithms, we don't draw the SQD but the boxplot. The small circles are outliers: they are outside the box. Often happens that an algorithm gets a certain result, but sometimes gets out of the way. Ok mi torna che figoooo. Compare A7 and A8. What is better? A7. Why is it clearly better? because its box is ompletely below the other. This is strict dominance. For probabilistic dominance, we have A2 and A3. It's possible that we don't have strict dominance, but also the contrary is true. Wait, how do we impose probabilistic dominance? That each quarter is better than the previous one. No. Each quartile MUST preceed the corresponing of the other one, ok. But ALSO, it has to preveed the NEXT quartile of the following. \line ok aspetta, ho capito. il secondo del primo deve essere del tutto sotto il primo del secondo.\par
Il terzo del rpimo deve essere meglio del secondo del secondo.\par
il quarto del primo deve essere meglio del terzo del secondo, ok, quando questo \'e8 vero, hai probabilistic dominance. Il rpimo \'e8 probabilistic dominant sull'altro.\par
7 -> Using a randomized algorithm depends on instance, time and seed of the pseudo random number generator. \par
8 -> You can classify algos in at least three ways.\line 1) Complete/exact algorithms. For every instance, it gives the optimum in finite time. The time depends on the size of the instance. Every instance basically has a time after which we are sure that the algorithm gives us the optimum. \par
2) Probabilistically approximately complete. Running the instance for a long time gives us the optimum or not? The probability converges to 1 as the time goes to infinity. SOME meteheuristics don't fall in this cathegory. Is this property interesting? \par
3) Essentially incomplete: finds the optimum for some instances with probability strictly lower that 1 as t goes to infinity. For many other instances, finds the optimum with pro = 1 when t goes to infinity.\par
9 -> alpha complete algorithm is an approximation algorithm. bla bla bla\par
11 -> Fix a certain quality. What happens for a certain time?\par
prendi il grafo di destra, x = 10, y = 30, dotted line: Il 30% delle istanze risolte in maniera ottima vengono risolte in meno di 10 secondi. La linea continua a crescere perch\'e9, se il 30% delle istanze le risolvi in tempo x, le risolvi di sicuro anche in tempo x+c.\par
13 -> Median = 0.5\par
14 -> The idea is that we can compare two algorithms, but what if there is no probabilistic dominance?\par
4 again -> Very small box and large whiskers and viceversa? First, the box is half of the insances (average half). Small box = stable algorithm. \par
14 -> minimization problem. if the difference is always negative, strict dominance. if sometimes it is, sometimes it is not, no guarantee. \par
\par
\par
\par
\par
\par
\par
\par
\par
\par
\par
\par
\par
}
 